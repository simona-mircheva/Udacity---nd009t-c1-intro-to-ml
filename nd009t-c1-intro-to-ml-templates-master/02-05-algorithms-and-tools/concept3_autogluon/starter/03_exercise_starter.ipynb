{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9520883-fb9c-42fd-8d73-d19e3a401c7f",
   "metadata": {},
   "source": [
    "Throughout this lesson, you've been trying different models on the same two datasets, wine and diabetes. Now, we're going to try our hand at accelerating this methodology by using AutoGluon. In this exercise, train two different AutonGluon models and see how they compare to previous iterations in exercise 1 and 2.\n",
    "\n",
    "You're tasked with completing the following steps:\n",
    "1. Load in the wine dataset from scikit learn.\n",
    "2. For the wine dataset, create a train and test split, 80% train / 20% test.\n",
    "3. Create a AutoGluon Classifier model with these hyper parameters:\n",
    "    1. time_limit: 120\n",
    "    2. presets: best_quality\n",
    "4. Output the model table summary\n",
    "5. Evaluate the trained model on the test dataset\n",
    "6. Load the diabetes dataset from scikit learn\n",
    "7. For the Diabetes dataset, create a train and test split, 80% train / 20% test.\n",
    "8. Create a AutoGluon Regression model with these hyper parameters:\n",
    "    1. eval_metric: r2\n",
    "    2. time_limit: 120\n",
    "    3. presets: best_quality\n",
    "9. Output the model table summary\n",
    "10. Evaluate the trained model on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0ac658-af67-4355-a789-147a1a98b7cd",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc846de2-0e72-4935-a786-ae65df4f2948",
   "metadata": {},
   "source": [
    "### Open up Sagemaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cbe42-87c5-4671-87e4-507764ad0ed4",
   "metadata": {},
   "source": [
    "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
    "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d158af04-dd1d-4e26-8e63-e81de4e6bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (21.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (58.5.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (0.37.0)\n",
      "Requirement already satisfied: mxnet<2.0.0 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (1.7.0.post2)\n",
      "Requirement already satisfied: bokeh==2.0.1 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (1.16.6)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (21.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (2.8.2)\n",
      "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (3.0.2)\n",
      "Requirement already satisfied: tornado>=5 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (6.1)\n",
      "Requirement already satisfied: pillow>=4.0 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from bokeh==2.0.1) (3.10.0.2)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from mxnet<2.0.0) (0.8.4)\n",
      "Requirement already satisfied: requests<2.19.0,>=2.18.4 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from mxnet<2.0.0) (2.18.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.0.1)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from packaging>=16.8->bokeh==2.0.1) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.16.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet<2.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet<2.0.0) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet<2.0.0) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet<2.0.0) (2021.10.8)\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-0.0.15-py3-none-any.whl (622 kB)\n",
      "Collecting distributed>=2.6.0\n",
      "  Downloading distributed-2021.11.1-py3-none-any.whl (793 kB)\n",
      "Collecting networkx<3.0,>=2.3\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.20.0-py3-none-any.whl (131 kB)\n",
      "Collecting openml\n",
      "  Downloading openml-0.12.2.tar.gz (119 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting dask>=2.6.0\n",
      "  Downloading dask-2021.11.1-py3-none-any.whl (1.0 MB)\n",
      "Collecting paramiko>=2.4\n",
      "  Downloading paramiko-2.8.0-py2.py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from autogluon) (0.8.4)\n",
      "Collecting autogluon-contrib-nlp\n",
      "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
      "Collecting lightgbm<4.0,>=3.0\n",
      "  Downloading lightgbm-3.3.1-py3-none-win_amd64.whl (1.0 MB)\n",
      "Collecting ConfigSpace<=0.4.10\n",
      "  Downloading ConfigSpace-0.4.10.tar.gz (882 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tqdm>=4.38.0\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from autogluon) (2.18.4)\n",
      "Requirement already satisfied: scipy>=1.3.3 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from autogluon) (1.7.2)\n",
      "Collecting cython\n",
      "  Downloading Cython-0.29.24-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: tornado>=5.0.1 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from autogluon) (6.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.4.3-cp39-cp39-win_amd64.whl (7.1 MB)\n",
      "Collecting gluoncv<0.9.0,>=0.5.0\n",
      "  Downloading gluoncv-0.8.0-py2.py3-none-any.whl (810 kB)\n",
      "Collecting catboost<0.25,>=0.23.0\n",
      "  Downloading catboost-0.24.4-cp39-none-win_amd64.whl (65.4 MB)\n",
      "Collecting Pillow<=6.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\user\\ml-nanodegree-venv\\scripts\\python.exe' 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-standalone-pip-an5r3zgt\\__env_pip__.zip\\pip' install --ignore-installed --no-user --prefix 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-rm8nj6jm\\overlay' --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- 'cython >= 0.29' 'numpy==1.14.5; python_version<'\"'\"'3.7'\"'\"'' 'numpy==1.16.0; python_version>='\"'\"'3.7'\"'\"'' setuptools setuptools_scm wheel\n",
      "       cwd: None\n",
      "  Complete output (2283 lines):\n",
      "  Ignoring numpy: markers 'python_version < \"3.7\"' don't match your environment\n",
      "  Collecting cython>=0.29\n",
      "    Using cached Cython-0.29.24-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "  Collecting numpy==1.16.0\n",
      "    Using cached numpy-1.16.0.zip (5.1 MB)\n",
      "    Preparing metadata (setup.py): started"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading Pillow-6.2.1.tar.gz (37.7 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas<2.0,>=1.0.0 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from autogluon) (1.3.4)\n",
      "Collecting scikit-learn<0.24,>=0.22.0\n",
      "  Downloading scikit-learn-0.23.2.tar.gz (7.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting cryptography>=2.8\n",
      "  Downloading cryptography-35.0.0-cp36-abi3-win_amd64.whl (2.1 MB)\n",
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from autogluon) (1.16.6)\n",
      "Collecting fastparquet==0.4.1\n",
      "  Downloading fastparquet-0.4.1.tar.gz (28.6 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyarrow<=1.0.0\n",
      "  Downloading pyarrow-1.0.0.tar.gz (1.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n",
      "  Downloading pyarrow-0.17.1.tar.gz (2.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n",
      "  Downloading pyarrow-0.17.0.tar.gz (3.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n",
      "  Downloading pyarrow-0.16.0.tar.gz (5.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n",
      "  Downloading pyarrow-0.15.1.tar.gz (5.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting psutil<=5.7.0,>=5.0.0\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting numba>=0.28\n",
      "  Downloading numba-0.54.1-cp39-cp39-win_amd64.whl (2.3 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from fastparquet==0.4.1->autogluon) (21.2)\n",
      "Collecting thrift>=0.11.0\n",
      "  Downloading thrift-0.15.0.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from fastparquet==0.4.1->autogluon) (1.16.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from ConfigSpace<=0.4.10->autogluon) (2.4.7)\n",
      "Collecting typing\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.0-cp39-cp39-win_amd64.whl (180 kB)\n",
      "Collecting fsspec>=0.6.0\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "Collecting toolz>=0.8.2\n",
      "  Downloading toolz-0.11.2-py3-none-any.whl (55 kB)\n",
      "Collecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting cloudpickle>=1.1.1\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\ml-nanodegree-venv\\lib\\site-packages (from dask>=2.6.0->autogluon) (6.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Preparing metadata (setup.py): finished with status 'done'\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-58.5.3-py3-none-any.whl (946 kB)\n",
      "  Collecting setuptools_scm\n",
      "    Using cached setuptools_scm-6.3.2-py3-none-any.whl (33 kB)\n",
      "  Collecting wheel\n",
      "    Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "  Collecting tomli>=1.0.0\n",
      "    Using cached tomli-1.2.2-py3-none-any.whl (12 kB)\n",
      "  Collecting packaging>=20.0\n",
      "    Using cached packaging-21.2-py3-none-any.whl (40 kB)\n",
      "  Collecting pyparsing<3,>=2.0.2\n",
      "    Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "  Building wheels for collected packages: numpy\n",
      "    Building wheel for numpy (setup.py): started\n",
      "    Building wheel for numpy (setup.py): still running...\n",
      "    Building wheel for numpy (setup.py): still running...\n",
      "    Building wheel for numpy (setup.py): finished with status 'error'\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\users\\user\\ml-nanodegree-venv\\scripts\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rn52g54m\\\\numpy_ad0c9935982a43768ed20383fa32d38d\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rn52g54m\\\\numpy_ad0c9935982a43768ed20383fa32d38d\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-wheel-3ppxb5s9'\n",
      "         cwd: C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-rn52g54m\\numpy_ad0c9935982a43768ed20383fa32d38d\\\n",
      "    Complete output (1893 lines):\n",
      "    Running from numpy source directory.\n",
      "    C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-rn52g54m\\numpy_ad0c9935982a43768ed20383fa32d38d\\numpy\\distutils\\misc_util.py:476: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "      return is_string(s) and ('*' in s or '?' is s)\n",
      "    blas_opt_info:\n",
      "    blas_mkl_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries mkl_rt not found in ['c:\\\\users\\\\user\\\\ml-nanodegree-venv\\\\lib', 'C:\\\\']\n",
      "      NOT AVAILABLE\n",
      "  \n",
      "    blis_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries blis not found in ['c:\\\\users\\\\user\\\\ml-nanodegree-venv\\\\lib', 'C:\\\\']\n",
      "      NOT AVAILABLE\n",
      "  \n",
      "    openblas_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries openblas not found in ['c:\\\\users\\\\user\\\\ml-nanodegree-venv\\\\lib', 'C:\\\\']\n",
      "    get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "    customize GnuFCompiler\n",
      "    Could not locate executable g77\n",
      "    Could not locate executable f77\n",
      "    customize IntelVisualFCompiler\n",
      "    Could not locate executable ifort\n",
      "    Could not locate executable ifl\n",
      "    customize AbsoftFCompiler\n",
      "    Could not locate executable f90\n",
      "    customize CompaqVisualFCompiler\n",
      "    Could not locate executable DF\n",
      "    customize IntelItaniumVisualFCompiler\n",
      "    Could not locate executable efl\n",
      "    customize Gnu95FCompiler\n",
      "    Could not locate executable gfortran\n",
      "    Could not locate executable f95\n",
      "    customize G95FCompiler\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "!pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dfefd6d-ed7f-46e3-a0c0-befda8d6aa23",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "this version of pandas is incompatible with numpy < 1.17.3\nyour numpy version is 1.16.6.\nPlease upgrade numpy to >= 1.17.3 to use this pandas version",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11064/992084465.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\ml-nanodegree-venv\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m from pandas.compat import (\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mnp_version_under1p18\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_np_version_under1p18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\ml-nanodegree-venv\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnp_array_datetime64_compat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\ml-nanodegree-venv\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_nlv\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_min_numpy_ver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     raise ImportError(\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;34mf\"this version of pandas is incompatible with numpy < {_min_numpy_ver}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;34mf\"your numpy version is {_np_version}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: this version of pandas is incompatible with numpy < 1.17.3\nyour numpy version is 1.16.6.\nPlease upgrade numpy to >= 1.17.3 to use this pandas version"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6fd8c-df16-4109-a7a8-6c6ccb2cdf29",
   "metadata": {},
   "source": [
    "## AutoGluon Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c70a0-c311-4cf7-befb-92641f071326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d674674-0c0f-4a2a-8d0a-c8b1fc4c11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(wine[\"data\"], columns = wine[\"feature_names\"])\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = wine[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee9c82-4e05-4952-8be9-7f823436d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205ac08-20cd-48c5-a90e-44960f6d81f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a classifier, autogluon will pick it up\n",
    "predictor = TabularPredictor(label=\"target\").fit(train_data=df_train, time_limit=120, presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b15550-b62b-4a80-857e-12710eee9e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the model's `score_val` in a bar chart to compare performance\n",
    "predictor.leaderboard(silent=True).plot(kind=\"bar\", x=\"model\", y=\"score_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d5630-84b5-4fbb-9b9a-08871ec4fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614c377-9f5b-4a2a-bc3c-0a049413b6e5",
   "metadata": {},
   "source": [
    "## AutoGluon Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe39b07-53b3-4576-b392-1a1df77b43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b9530-5bcd-40b4-a1f0-e6ad32bac145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "dfd = pd.DataFrame(diabetes[\"data\"], columns = diabetes[\"feature_names\"])\n",
    "\n",
    "# Include the target as well\n",
    "dfd['target'] = diabetes[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9b895-00a5-48b9-951f-e36436255d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "dfd_train, dfd_test = train_test_split(dfd, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f9d06-9436-4a4e-988d-f0ad00b26e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a regression, autogluon will pick it up\n",
    "predictor = TabularPredictor(label=\"target\", problem_type=\"regression\", eval_metric=\"r2\").fit(train_data=dfd_train,\n",
    "    time_limit=120, presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09621b-9ce7-4889-bcf9-c9b8687438ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc37fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the model's `score_val` in a bar chart to compare performance\n",
    "predictor.leaderboard(silent=True).plot(kind=\"bar\", x=\"model\", y=\"score_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c39401-a8cb-4e6c-aabb-c318f384e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(dfd_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
